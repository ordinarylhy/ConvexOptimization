{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.25 Constrained maximum likelihood estimate of mean and covariance\n",
    "\n",
    "Change of variable $\\Sigma^{-1}$ and $\\Sigma^{-1}\\mu$ \n",
    "\n",
    "Note that matrix inversion is a convex operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20 # Dimension of input\n",
    "#np.random.seed(0) # Set random variable seed\n",
    "\n",
    "# Generate distribution with true mean mu\n",
    "# and true covariance Sigma such that Sigma^(-1)mu >= 0\n",
    "\n",
    "Sigma = np.random.rand(n, n)\n",
    "Sigma = 0.5 * (Sigma + Sigma.T)\n",
    "Sigma = Sigma + n * np.eye(n)\n",
    "temp_mu = np.random.rand(n, 1)\n",
    "res = np.linalg.solve(Sigma, temp_mu)\n",
    "res = np.maximum(res, 0)\n",
    "mu = Sigma.dot(res).flatten()\n",
    "\n",
    "# Draw N random samples from distribution\n",
    "# N = 25\n",
    "N = 500\n",
    "X = np.random.multivariate_normal(mu, Sigma, N).T\n",
    "\n",
    "\n",
    "#X = np.random.randn(n, N)\n",
    "#MU = np.zeros((n, N))\n",
    "#for i in range(N):\n",
    "#    MU[:, i] = mu.flatten()\n",
    "#Sq = sqrtm(Sigma)\n",
    "#X = Sq.dot(X)\n",
    "#X = X + MU\n",
    "\n",
    "# n: dimension of vector\n",
    "# N: number of samples from distribution\n",
    "# X: matrix containing  N samples from distribution (n x N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - large complementary slackness residual: 2.032198\n"
     ]
    }
   ],
   "source": [
    "Omega = cp.Variable((n,n), PSD=True) # The precision matrix, Ω, is defined to be the inverse of the covariance matrix\n",
    "h = cp.Variable(n, nonneg=True) # h = \\Sigma^{-1}\\mu\n",
    "objective = cp.Maximize(\n",
    "    N * cp.log_det(Omega) \n",
    "    - cp.sum([cp.quad_form(x, Omega) for x in X.T])\n",
    "    + 2 * cp.sum(X.T @ h)\n",
    "    - N * cp.matrix_frac(h, Omega) # h^T Omega^{-1} h\n",
    ")\n",
    "constraints = []\n",
    "prob = cp.Problem(objective, constraints)\n",
    "result = prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance between true mean and estimated mean: 0.7770216241238542\n",
      "Frobenius norm between true cov and estimated cov: 18.413828955023643\n"
     ]
    }
   ],
   "source": [
    "Sigma_est = np.linalg.inv(Omega.value)\n",
    "mu_est = Sigma_est @ h.value\n",
    "print('l2 distance between true mean and estimated mean:', np.linalg.norm(mu - mu_est, 2))\n",
    "print('Frobenius norm between true cov and estimated cov:', np.linalg.norm(Sigma - Sigma_est, 'fro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 distance between true mean and empirical mean: 0.8682822402125457\n",
      "Frobenius norm between true cov and empirical cov: 18.47092641169903\n"
     ]
    }
   ],
   "source": [
    "mu_emp = np.mean(X, axis=1)\n",
    "print('l2 distance between true mean and empirical mean:', np.linalg.norm(mu - mu_emp, 2))\n",
    "Sigma_emp = (X.T - mu_emp).T @ (X.T - mu_emp) / N\n",
    "print('Frobenius norm between true cov and empirical cov:', np.linalg.norm(Sigma - Sigma_emp, 'fro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - large complementary slackness residual: 3.669426\n"
     ]
    }
   ],
   "source": [
    "# without the constraint that \\Sigma^{-1}\\mu >= 0 \n",
    "Omega = cp.Variable((n,n), PSD=True) # The precision matrix, Ω, is defined to be the inverse of the covariance matrix\n",
    "h = cp.Variable(n) # h = \\Sigma^{-1}\\mu\n",
    "objective = cp.Maximize(\n",
    "    N * cp.log_det(Omega) \n",
    "    - cp.sum([cp.quad_form(x, Omega) for x in X.T])\n",
    "    + 2 * cp.sum(X.T @ h)\n",
    "    - N * cp.matrix_frac(h, Omega)\n",
    ")\n",
    "constraints = []\n",
    "prob = cp.Problem(objective, constraints)\n",
    "result = prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004200840206031278\n",
      "9.05651767063618e-06\n"
     ]
    }
   ],
   "source": [
    "# verify the convex optimization solution agrees with the analytical solution\n",
    "print(np.linalg.norm(np.linalg.inv(Omega.value) @ h.value - mu_emp, 2))\n",
    "print(np.linalg.norm(np.linalg.inv(Omega.value) - Sigma_emp, 'fro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
